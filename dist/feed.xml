<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Awesome Gaussian Splatting Latest Papers</title><link>https://yourusername.github.io/Awesome-Gaussian-Splatting</link><description>Daily updated feed of the latest Gaussian Splatting papers from arXiv.</description><language>en-us</language><lastBuildDate>Mon, 09 Feb 2026 12:59:30 +0000</lastBuildDate><atom:link href="https://yourusername.github.io/Awesome-Gaussian-Splatting/feed.xml" rel="self" type="application/rss+xml" /><item><title>DynFOA: Generating First-Order Ambisonics with Conditional Diffusion for Dynamic and Acoustically Complex 360-Degree Videos</title><link>https://arxiv.org/abs/2602.06846</link><guid>https://arxiv.org/abs/2602.06846</guid><description>Spatial audio is crucial for creating compelling immersive 360-degree video experiences. However, generating realistic spatial audio, such as first-order ambisonics (FOA), from 360-degree videos in complex acoustic scenes remains challenging. Existing methods often overlook the dynamic nature and acoustic complexity of 360-degree scenes, fail to fully account for dynamic sound sources, and neglect complex environmental effects such as occlusion, reflections, and reverberation, which are influ...</description><pubDate>Fri, 06 Feb 2026 16:36:46 +0000</pubDate><category>Dynamic</category><category>Generation</category><category>Medical</category><category>Segmentation</category><author>Ziyu Luo, Lin Chen, Qiang Qu, Xiaoming Chen, Yiran Shen</author></item><item><title>GaussianPOP: Principled Simplification Framework for Compact 3D Gaussian Splatting via Error Quantification</title><link>https://arxiv.org/abs/2602.06830</link><guid>https://arxiv.org/abs/2602.06830</guid><description>Existing 3D Gaussian Splatting simplification methods commonly use importance scores, such as blending weights or sensitivity, to identify redundant Gaussians. However, these scores are not driven by visual error metrics, often leading to suboptimal trade-offs between compactness and rendering fidelity. We present GaussianPOP, a principled simplification framework based on analytical Gaussian error quantification. Our key contribution is a novel error criterion, derived directly from the 3DGS...</description><pubDate>Fri, 06 Feb 2026 16:17:41 +0000</pubDate><category>Compression</category><category>Medical</category><author>Soonbin Lee, Yeong-Gyu Kim, Simon Sasse, Tomas M. Borges, Yago Sanchez</author><author>Soonbin Lee, Yeong-Gyu Kim, Simon Sasse, Tomas M. Borges, Yago Sanchez et al.</author></item><item><title>TFusionOcc: Student's t-Distribution Based Object-Centric Multi-Sensor Fusion Framework for 3D Occupancy Prediction</title><link>https://arxiv.org/abs/2602.06400</link><guid>https://arxiv.org/abs/2602.06400</guid><description>3D semantic occupancy prediction enables autonomous vehicles (AVs) to perceive fine-grained geometric and semantic structure of their surroundings from onboard sensors, which is essential for safe decision-making and navigation. Recent models for 3D semantic occupancy prediction have successfully addressed the challenge of describing real-world objects with varied shapes and classes. However, the intermediate representations used by existing methods for 3D semantic occupancy prediction rely h...</description><pubDate>Fri, 06 Feb 2026 05:43:42 +0000</pubDate><category>Autonomous Driving</category><category>Dynamic</category><category>Medical</category><category>Robotics</category><category>Segmentation</category><author>Zhenxing Ming, Julie Stephany Berrio, Mao Shan, Stewart Worrall</author></item><item><title>Uncertainty-Aware 4D Gaussian Splatting for Monocular Occluded Human Rendering</title><link>https://arxiv.org/abs/2602.06343</link><guid>https://arxiv.org/abs/2602.06343</guid><description>High-fidelity rendering of dynamic humans from monocular videos typically degrades catastrophically under occlusions. Existing solutions incorporate external priors-either hallucinating missing content via generative models, which induces severe temporal flickering, or imposing rigid geometric heuristics that fail to capture diverse appearances. To this end, we reformulate the task as a Maximum A Posteriori estimation problem under heteroscedastic observation noise. In this paper, we propose ...</description><pubDate>Fri, 06 Feb 2026 03:14:37 +0000</pubDate><category>Dynamic</category><category>Generation</category><category>Medical</category><category>Physics</category><author>Weiquan Wang, Feifei Shao, Lin Li, Zhen Wang, Jun Xiao</author><author>Weiquan Wang, Feifei Shao, Lin Li, Zhen Wang, Jun Xiao et al.</author></item><item><title>From Blurry to Believable: Enhancing Low-quality Talking Heads with 3D Generative Priors</title><link>https://arxiv.org/abs/2602.06122</link><guid>https://arxiv.org/abs/2602.06122</guid><description>Creating high-fidelity, animatable 3D talking heads is crucial for immersive applications, yet often hindered by the prevalence of low-quality image or video sources, which yield poor 3D reconstructions. In this paper, we introduce SuperHead, a novel framework for enhancing low-resolution, animatable 3D head avatars. The core challenge lies in synthesizing high-quality geometry and textures, while ensuring both 3D and temporal consistency during animation and preserving subject identity. Desp...</description><pubDate>Thu, 05 Feb 2026 19:00:50 +0000</pubDate><category>Avatar</category><category>Dynamic</category><category>Generation</category><category>Medical</category><author>Ding-Jiun Huang, Yuanhao Wang, Shao-Ji Yuan, Albert Mosella-Montoro, Francisco Vicente Carrasco</author><author>Ding-Jiun Huang, Yuanhao Wang, Shao-Ji Yuan, Albert Mosella-Montoro, Francisco Vicente Carrasco et al.</author></item><item><title>Splat and Distill: Augmenting Teachers with Feed-Forward 3D Reconstruction For 3D-Aware Distillation</title><link>https://arxiv.org/abs/2602.06032</link><guid>https://arxiv.org/abs/2602.06032</guid><description>Vision Foundation Models (VFMs) have achieved remarkable success when applied to various downstream 2D tasks. Despite their effectiveness, they often exhibit a critical lack of 3D awareness. To this end, we introduce Splat and Distill, a framework that instills robust 3D awareness into 2D VFMs by augmenting the teacher model with a fast, feed-forward 3D reconstruction pipeline. Given 2D features produced by a teacher model, our method first lifts these features into an explicit 3D Gaussian re...</description><pubDate>Thu, 05 Feb 2026 18:59:05 +0000</pubDate><category>Dynamic</category><category>Medical</category><category>Rendering</category><category>Segmentation</category><author>David Shavin, Sagie Benaim</author></item><item><title>NVS-HO: A Benchmark for Novel View Synthesis of Handheld Objects</title><link>https://arxiv.org/abs/2602.05822</link><guid>https://arxiv.org/abs/2602.05822</guid><description>We propose NVS-HO, the first benchmark designed for novel view synthesis of handheld objects in real-world environments using only RGB inputs. Each object is recorded in two complementary RGB sequences: (1) a handheld sequence, where the object is manipulated in front of a static camera, and (2) a board sequence, where the object is fixed on a ChArUco board to provide accurate camera poses via marker detection. The goal of NVS-HO is to learn a NVS model that captures the full appearance of an...</description><pubDate>Thu, 05 Feb 2026 16:13:53 +0000</pubDate><category>Medical</category><category>Rendering</category><category>Robotics</category><author>Musawar Ali, Manuel Carranza-García, Nicola Fioraio, Samuele Salti, Luigi Di Stefano</author></item><item><title>Unified Sensor Simulation for Autonomous Driving</title><link>https://arxiv.org/abs/2602.05617</link><guid>https://arxiv.org/abs/2602.05617</guid><description>In this work, we introduce \textbf{XSIM}, a sensor simulation framework for autonomous driving. XSIM extends 3DGUT splatting with a generalized rolling-shutter modeling tailored for autonomous driving applications. Our framework provides a unified and flexible formulation for appearance and geometric sensor modeling, enabling rendering of complex sensor distortions in dynamic environments. We identify spherical cameras, such as LiDARs, as a critical edge case for existing 3DGUT splatting due ...</description><pubDate>Thu, 05 Feb 2026 12:52:46 +0000</pubDate><category>Autonomous Driving</category><category>Dynamic</category><category>Medical</category><category>Physics</category><author>Nikolay Patakin, Arsenii Shirokov, Anton Konushin, Dmitry Senushkin</author></item><item><title>PoseGaussian: Pose-Driven Novel View Synthesis for Robust 3D Human Reconstruction</title><link>https://arxiv.org/abs/2602.05190</link><guid>https://arxiv.org/abs/2602.05190</guid><description>We propose PoseGaussian, a pose-guided Gaussian Splatting framework for high-fidelity human novel view synthesis. Human body pose serves a dual purpose in our design: as a structural prior, it is fused with a color encoder to refine depth estimation; as a temporal cue, it is processed by a dedicated pose encoder to enhance temporal consistency across frames. These components are integrated into a fully differentiable, end-to-end trainable pipeline. Unlike prior works that use pose only as a c...</description><pubDate>Thu, 05 Feb 2026 01:34:52 +0000</pubDate><category>Avatar</category><category>Dynamic</category><category>Rendering</category><author>Ju Shen, Chen Chen, Tam V. Nguyen, Vijayan K. Asari</author></item><item><title>QuantumGS: Quantum Encoding Framework for Gaussian Splatting</title><link>https://arxiv.org/abs/2602.05047</link><guid>https://arxiv.org/abs/2602.05047</guid><description>Recent advances in neural rendering, particularly 3D Gaussian Splatting (3DGS), have enabled real-time rendering of complex scenes. However, standard 3DGS relies on spherical harmonics, which often struggle to accurately capture high-frequency view-dependent effects such as sharp reflections and transparency. While hybrid approaches like Viewing Direction Gaussian Splatting (VDGS) mitigate this limitation using classical Multi-Layer Perceptrons (MLPs), they remain limited by the expressivity ...</description><pubDate>Wed, 04 Feb 2026 20:56:42 +0000</pubDate><category>Generation</category><category>Rendering</category><author>Grzegorz Wilczyński, Rafał Tobiasz, Paweł Gora, Marcin Mazur, Przemysław Spurek</author></item><item><title>Nix and Fix: Targeting 1000x Compression of 3D Gaussian Splatting with Diffusion Models</title><link>https://arxiv.org/abs/2602.04549</link><guid>https://arxiv.org/abs/2602.04549</guid><description>3D Gaussian Splatting (3DGS) revolutionized novel view rendering. Instead of inferring from dense spatial points, as implicit representations do, 3DGS uses sparse Gaussians. This enables real-time performance but increases space requirements, hindering applications such as immersive communication. 3DGS compression emerged as a field aimed at alleviating this issue. While impressive progress has been made, at low rates, compression introduces artifacts that degrade visual quality significantly...</description><pubDate>Wed, 04 Feb 2026 13:39:00 +0000</pubDate><category>Compression</category><category>Generation</category><category>Medical</category><category>Rendering</category><author>Cem Eteke, Enzo Tartaglione</author></item><item><title>VecSet-Edit: Unleashing Pre-trained LRM for Mesh Editing from Single Image</title><link>https://arxiv.org/abs/2602.04349</link><guid>https://arxiv.org/abs/2602.04349</guid><description>3D editing has emerged as a critical research area to provide users with flexible control over 3D assets. While current editing approaches predominantly focus on 3D Gaussian Splatting or multi-view images, the direct editing of 3D meshes remains underexplored. Prior attempts, such as VoxHammer, rely on voxel-based representations that suffer from limited resolution and necessitate labor-intensive 3D mask. To address these limitations, we propose \textbf{VecSet-Edit}, the first pipeline that l...</description><pubDate>Wed, 04 Feb 2026 09:16:12 +0000</pubDate><category>Compression</category><category>Editing</category><category>Generation</category><category>Medical</category><category>Mesh</category><category>Sparse View</category><author>Teng-Fang Hsiao, Bo-Kai Ruan, Yu-Lun Liu, Hong-Han Shuai</author></item><item><title>JOintGS: Joint Optimization of Cameras, Bodies and 3D Gaussians for In-the-Wild Monocular Reconstruction</title><link>https://arxiv.org/abs/2602.04317</link><guid>https://arxiv.org/abs/2602.04317</guid><description>Reconstructing high-fidelity animatable 3D human avatars from monocular RGB videos remains challenging, particularly in unconstrained in-the-wild scenarios where camera parameters and human poses from off-the-shelf methods (e.g., COLMAP, HMR2.0) are often inaccurate. Splatting (3DGS) advances demonstrate impressive rendering quality and real-time performance, they critically depend on precise camera calibration and pose annotations, limiting their applicability in real-world settings. We pres...</description><pubDate>Wed, 04 Feb 2026 08:33:51 +0000</pubDate><category>Avatar</category><category>Dynamic</category><category>Physics</category><category>Rendering</category><author>Zihan Lou, Jinlong Fan, Sihan Ma, Yuxiang Yang, Jing Zhang</author></item><item><title>SkeletonGaussian: Editable 4D Generation through Gaussian Skeletonization</title><link>https://arxiv.org/abs/2602.04271</link><guid>https://arxiv.org/abs/2602.04271</guid><description>4D generation has made remarkable progress in synthesizing dynamic 3D objects from input text, images, or videos. However, existing methods often represent motion as an implicit deformation field, which limits direct control and editability. To address this issue, we propose SkeletonGaussian, a novel framework for generating editable dynamic 3D Gaussians from monocular video input. Our approach introduces a hierarchical articulated representation that decomposes motion into sparse rigid motio...</description><pubDate>Wed, 04 Feb 2026 07:00:44 +0000</pubDate><category>Dynamic</category><category>Editing</category><category>Generation</category><category>Medical</category><category>Physics</category><author>Lifan Wu, Ruijie Zhu, Yubo Ai, Tianzhu Zhang</author></item><item><title>Towards Next-Generation SLAM: A Survey on 3DGS-SLAM Focusing on Performance, Robustness, and Future Directions</title><link>https://arxiv.org/abs/2602.04251</link><guid>https://arxiv.org/abs/2602.04251</guid><description>Traditional Simultaneous Localization and Mapping (SLAM) systems often face limitations including coarse rendering quality, insufficient recovery of scene details, and poor robustness in dynamic environments. 3D Gaussian Splatting (3DGS), with its efficient explicit representation and high-quality rendering capabilities, offers a new reconstruction paradigm for SLAM. This survey comprehensively reviews key technical approaches for integrating 3DGS with SLAM. We analyze performance optimizatio...</description><pubDate>Wed, 04 Feb 2026 06:20:22 +0000</pubDate><category>Dynamic</category><category>Generation</category><category>SLAM</category><author>Li Wang, Ruixuan Gong, Yumo Han, Lei Yang, Lu Yang</author><author>Li Wang, Ruixuan Gong, Yumo Han, Lei Yang, Lu Yang et al.</author></item><item><title>AnyStyle: Single-Pass Multimodal Stylization for 3D Gaussian Splatting</title><link>https://arxiv.org/abs/2602.04043</link><guid>https://arxiv.org/abs/2602.04043</guid><description>The growing demand for rapid and scalable 3D asset creation has driven interest in feed-forward 3D reconstruction methods, with 3D Gaussian Splatting (3DGS) emerging as an effective scene representation. While recent approaches have demonstrated pose-free reconstruction from unposed image collections, integrating stylization or appearance control into such pipelines remains underexplored. Existing attempts largely rely on image-based conditioning, which limits both controllability and flexibi...</description><pubDate>Tue, 03 Feb 2026 22:19:58 +0000</pubDate><category>Editing</category><category>Language</category><author>Joanna Kaleta, Bartosz Świrta, Kacper Kania, Przemysław Spurek, Marek Kowalski</author></item><item><title>Constrained Dynamic Gaussian Splatting</title><link>https://arxiv.org/abs/2602.03538</link><guid>https://arxiv.org/abs/2602.03538</guid><description>While Dynamic Gaussian Splatting enables high-fidelity 4D reconstruction, its deployment is severely hindered by a fundamental dilemma: unconstrained densification leads to excessive memory consumption incompatible with edge devices, whereas heuristic pruning fails to achieve optimal rendering quality under preset Gaussian budgets. In this work, we propose Constrained Dynamic Gaussian Splatting (CDGS), a novel framework that formulates dynamic scene reconstruction as a budget-constrained opti...</description><pubDate>Tue, 03 Feb 2026 13:53:29 +0000</pubDate><category>Compression</category><category>Dynamic</category><author>Zihan Zheng, Zhenglong Wu, Xuanxuan Wang, Houqiang Zhong, Xiaoyun Zhang</author><author>Zihan Zheng, Zhenglong Wu, Xuanxuan Wang, Houqiang Zhong, Xiaoyun Zhang et al.</author></item><item><title>Pi-GS: Sparse-View Gaussian Splatting with Dense π^3 Initialization</title><link>https://arxiv.org/abs/2602.03327</link><guid>https://arxiv.org/abs/2602.03327</guid><description>Novel view synthesis has evolved rapidly, advancing from Neural Radiance Fields to 3D Gaussian Splatting (3DGS), which offers real-time rendering and rapid training without compromising visual fidelity. However, 3DGS relies heavily on accurate camera poses and high-quality point cloud initialization, which are difficult to obtain in sparse-view scenarios. While traditional Structure from Motion (SfM) pipelines often fail in these settings, existing learning-based point estimation alternatives...</description><pubDate>Tue, 03 Feb 2026 09:55:03 +0000</pubDate><category>Dynamic</category><category>Rendering</category><category>Sparse View</category><author>Manuel Hofer, Markus Steinberger, Thomas Köhler</author></item><item><title>WebSplatter: Enabling Cross-Device Efficient Gaussian Splatting in Web Browsers via WebGPU</title><link>https://arxiv.org/abs/2602.03207</link><guid>https://arxiv.org/abs/2602.03207</guid><description>We present WebSplatter, an end-to-end GPU rendering pipeline for the heterogeneous web ecosystem. Unlike naive ports, WebSplatter introduces a wait-free hierarchical radix sort that circumvents the lack of global atomics in WebGPU, ensuring deterministic execution across diverse hardware. Furthermore, we propose an opacity-aware geometry culling stage that dynamically prunes splats before rasterization, significantly reducing overdraw and peak memory footprint. Evaluation demonstrates that We...</description><pubDate>Tue, 03 Feb 2026 07:18:40 +0000</pubDate><category>Dynamic</category><author>Yudong Han, Chao Xu, Xiaodan Ye, Weichen Bi, Zilong Dong</author><author>Yudong Han, Chao Xu, Xiaodan Ye, Weichen Bi, Zilong Dong et al.</author></item><item><title>SharpTimeGS: Sharp and Stable Dynamic Gaussian Splatting via Lifespan Modulation</title><link>https://arxiv.org/abs/2602.02989</link><guid>https://arxiv.org/abs/2602.02989</guid><description>Novel view synthesis of dynamic scenes is fundamental to achieving photorealistic 4D reconstruction and immersive visual experiences. Recent progress in Gaussian-based representations has significantly improved real-time rendering quality, yet existing methods still struggle to maintain a balance between long-term static and short-term dynamic regions in both representation and optimization. To address this, we present SharpTimeGS, a lifespan-aware 4D Gaussian framework that achieves temporal...</description><pubDate>Tue, 03 Feb 2026 01:50:59 +0000</pubDate><category>Compression</category><category>Dynamic</category><category>Medical</category><category>Rendering</category><author>Zhanfeng Liao, Jiajun Zhang, Hanzhang Tu, Zhixi Wang, Yunqi Gao</author><author>Zhanfeng Liao, Jiajun Zhang, Hanzhang Tu, Zhixi Wang, Yunqi Gao et al.</author></item><item><title>SoMA: A Real-to-Sim Neural Simulator for Robotic Soft-body Manipulation</title><link>https://arxiv.org/abs/2602.02402</link><guid>https://arxiv.org/abs/2602.02402</guid><description>Simulating deformable objects under rich interactions remains a fundamental challenge for real-to-sim robot manipulation, with dynamics jointly driven by environmental effects and robot actions. Existing simulators rely on predefined physics or data-driven dynamics without robot-conditioned control, limiting accuracy, stability, and generalization. This paper presents SoMA, a 3D Gaussian Splat simulator for soft-body manipulation. SoMA couples deformable dynamics, environmental forces, and ro...</description><pubDate>Mon, 02 Feb 2026 17:59:31 +0000</pubDate><category>Dynamic</category><category>Editing</category><category>Physics</category><category>Robotics</category><author>Mu Huang, Hui Wang, Kerui Ren, Linning Xu, Yunsong Zhou</author><author>Mu Huang, Hui Wang, Kerui Ren, Linning Xu, Yunsong Zhou et al.</author></item><item><title>Intellectual Property Protection for 3D Gaussian Splatting Assets: A Survey</title><link>https://arxiv.org/abs/2602.03878</link><guid>https://arxiv.org/abs/2602.03878</guid><description>3D Gaussian Splatting (3DGS) has become a mainstream representation for real-time 3D scene synthesis, enabling applications in virtual and augmented reality, robotics, and 3D content creation. Its rising commercial value and explicit parametric structure raise emerging intellectual property (IP) protection concerns, prompting a surge of research on 3DGS IP protection. However, current progress remains fragmented, lacking a unified view of the underlying mechanisms, protection paradigms, and r...</description><pubDate>Mon, 02 Feb 2026 16:27:51 +0000</pubDate><category>Generation</category><category>Robotics</category><author>Longjie Zhao, Ziming Hong, Jiaxin Huang, Runnan Chen, Mingming Gong</author><author>Longjie Zhao, Ziming Hong, Jiaxin Huang, Runnan Chen, Mingming Gong et al.</author></item><item><title>UrbanGS: A Scalable and Efficient Architecture for Geometrically Accurate Large-Scene Reconstruction</title><link>https://arxiv.org/abs/2602.02089</link><guid>https://arxiv.org/abs/2602.02089</guid><description>While 3D Gaussian Splatting (3DGS) enables high-quality, real-time rendering for bounded scenes, its extension to large-scale urban environments gives rise to critical challenges in terms of geometric consistency, memory efficiency, and computational scalability. To address these issues, we present UrbanGS, a scalable reconstruction framework that effectively tackles these challenges for city-scale applications. First, we propose a Depth-Consistent D-Normal Regularization module. Unlike exist...</description><pubDate>Mon, 02 Feb 2026 13:35:16 +0000</pubDate><category>Compression</category><category>Dynamic</category><category>Rendering</category><author>Changbai Li, Haodong Zhu, Hanlin Chen, Xiuping Liang, Tongfei Chen</author><author>Changbai Li, Haodong Zhu, Hanlin Chen, Xiuping Liang, Tongfei Chen et al.</author></item><item><title>SurfSplat: Conquering Feedforward 2D Gaussian Splatting with Surface Continuity Priors</title><link>https://arxiv.org/abs/2602.02000</link><guid>https://arxiv.org/abs/2602.02000</guid><description>Reconstructing 3D scenes from sparse images remains a challenging task due to the difficulty of recovering accurate geometry and texture without optimization. Recent approaches leverage generalizable models to generate 3D scenes using 3D Gaussian Splatting (3DGS) primitive. However, they often fail to produce continuous surfaces and instead yield discrete, color-biased point clouds that appear plausible at normal resolution but reveal severe artifacts under close-up views. To address this iss...</description><pubDate>Mon, 02 Feb 2026 11:58:26 +0000</pubDate><category>Generation</category><category>Medical</category><author>Bing He, Jingnan Gao, Yunuo Chen, Ning Cao, Gang Chen</author><author>Bing He, Jingnan Gao, Yunuo Chen, Ning Cao, Gang Chen et al.</author></item><item><title>CloDS: Visual-Only Unsupervised Cloth Dynamics Learning in Unknown Conditions</title><link>https://arxiv.org/abs/2602.01844</link><guid>https://arxiv.org/abs/2602.01844</guid><description>Deep learning has demonstrated remarkable capabilities in simulating complex dynamic systems. However, existing methods require known physical properties as supervision or inputs, limiting their applicability under unknown conditions. To explore this challenge, we introduce Cloth Dynamics Grounding (CDG), a novel scenario for unsupervised learning of cloth dynamics from multi-view visual observations. We further propose Cloth Dynamics Splatting (CloDS), an unsupervised dynamic learning framew...</description><pubDate>Mon, 02 Feb 2026 09:16:16 +0000</pubDate><category>Dynamic</category><category>Mesh</category><category>Physics</category><author>Yuliang Zhan, Jian Li, Wenbing Huang, Wenbing Huang, Yang Liu</author><author>Yuliang Zhan, Jian Li, Wenbing Huang, Wenbing Huang, Yang Liu et al.</author></item><item><title>OFERA: Blendshape-driven 3D Gaussian Control for Occluded Facial Expression to Realistic Avatars in VR</title><link>https://arxiv.org/abs/2602.01748</link><guid>https://arxiv.org/abs/2602.01748</guid><description>We propose OFERA, a novel framework for real-time expression control of photorealistic Gaussian head avatars for VR headset users. Existing approaches attempt to recover occluded facial expressions using additional sensors or internal cameras, but sensor-based methods increase device weight and discomfort, while camera-based methods raise privacy concerns and suffer from limited access to raw data. To overcome these limitations, we leverage the blendshape signals provided by commercial VR hea...</description><pubDate>Mon, 02 Feb 2026 07:34:15 +0000</pubDate><category>Avatar</category><category>Medical</category><author>Seokhwan Yang, Boram Yoon, Seoyoung Kang, Hail Song, Woontack Woo</author></item><item><title>FastPhysGS: Accelerating Physics-based Dynamic 3DGS Simulation via Interior Completion and Adaptive Optimization</title><link>https://arxiv.org/abs/2602.01723</link><guid>https://arxiv.org/abs/2602.01723</guid><description>Extending 3D Gaussian Splatting (3DGS) to 4D physical simulation remains challenging. Based on the Material Point Method (MPM), existing methods either rely on manual parameter tuning or distill dynamics from video diffusion models, limiting the generalization and optimization efficiency. Recent attempts using LLMs/VLMs suffer from a text/image-to-3D perceptual gap, yielding unstable physics behavior. In addition, they often ignore the surface structure of 3DGS, leading to implausible motion....</description><pubDate>Mon, 02 Feb 2026 07:00:42 +0000</pubDate><category>Dynamic</category><category>Generation</category><category>Physics</category><category>Segmentation</category><author>Yikun Ma, Yiqing Li, Jingwen Ye, Zhongkai Wu, Weidong Zhang</author><author>Yikun Ma, Yiqing Li, Jingwen Ye, Zhongkai Wu, Weidong Zhang et al.</author></item><item><title>VRGaussianAvatar: Integrating 3D Gaussian Avatars into VR</title><link>https://arxiv.org/abs/2602.01674</link><guid>https://arxiv.org/abs/2602.01674</guid><description>We present VRGaussianAvatar, an integrated system that enables real-time full-body 3D Gaussian Splatting (3DGS) avatars in virtual reality using only head-mounted display (HMD) tracking signals. The system adopts a parallel pipeline with a VR Frontend and a GA Backend. The VR Frontend uses inverse kinematics to estimate full-body pose and streams the resulting pose along with stereo camera parameters to the backend. The GA Backend stereoscopically renders a 3DGS avatar reconstructed from a si...</description><pubDate>Mon, 02 Feb 2026 05:42:40 +0000</pubDate><category>Avatar</category><category>Medical</category><category>Mesh</category><category>Sparse View</category><author>Hail Song, Boram Yoon, Seokhwan Yang, Seoyoung Kang, Hyunjeong Kim</author><author>Hail Song, Boram Yoon, Seokhwan Yang, Seoyoung Kang, Hyunjeong Kim et al.</author></item><item><title>MarkCleaner: High-Fidelity Watermark Removal via Imperceptible Micro-Geometric Perturbation</title><link>https://arxiv.org/abs/2602.01513</link><guid>https://arxiv.org/abs/2602.01513</guid><description>Semantic watermarks exhibit strong robustness against conventional image-space attacks. In this work, we show that such robustness does not survive under micro-geometric perturbations: spatial displacements can remove watermarks by breaking the phase alignment. Motivated by this observation, we introduce MarkCleaner, a watermark removal framework that avoids semantic drift caused by regeneration-based watermark removal. Specifically, MarkCleaner is trained with micro-geometry-perturbed superv...</description><pubDate>Mon, 02 Feb 2026 01:03:21 +0000</pubDate><category>Generation</category><category>Medical</category><category>Segmentation</category><author>Xiaoxi Kong, Jieyu Yuan, Pengdi Chen, Yuanlin Zhang, Chongyi Li</author><author>Xiaoxi Kong, Jieyu Yuan, Pengdi Chen, Yuanlin Zhang, Chongyi Li et al.</author></item><item><title>Position: 3D Gaussian Splatting Watermarking Should Be Scenario-Driven and Threat-Model Explicit</title><link>https://arxiv.org/abs/2602.02602</link><guid>https://arxiv.org/abs/2602.02602</guid><description>3D content acquisition and creation are expanding rapidly in the new era of machine learning and AI. 3D Gaussian Splatting (3DGS) has become a promising high-fidelity and real-time representation for 3D content. Similar to the initial wave of digital audio-visual content at the turn of the millennium, the demand for intellectual property protection is also increasing, since explicit and editable 3D parameterization makes unauthorized use and dissemination easier. In this position paper, we ar...</description><pubDate>Sun, 01 Feb 2026 21:45:06 +0000</pubDate><category>Medical</category><author>Yangfan Deng, Anirudh Nakra, Min Wu</author></item><item><title>Split&amp;Splat: Zero-Shot Panoptic Segmentation via Explicit Instance Modeling and 3D Gaussian Splatting</title><link>https://arxiv.org/abs/2602.03809</link><guid>https://arxiv.org/abs/2602.03809</guid><description>3D Gaussian Splatting (GS) enables fast and high-quality scene reconstruction, but it lacks an object-consistent and semantically aware structure. We propose Split&amp;Splat, a framework for panoptic scene reconstruction using 3DGS. Our approach explicitly models object instances. It first propagates instance masks across views using depth, thus producing view-consistent 2D masks. Each object is then reconstructed independently and merged back into the scene while refining its boundaries. Finally...</description><pubDate>Sun, 01 Feb 2026 20:10:37 +0000</pubDate><category>Editing</category><category>Medical</category><category>Segmentation</category><author>Leonardo Monchieri, Elena Camuffo, Francesco Barbato, Pietro Zanuttigh, Simone Milani</author></item><item><title>Radioactive 3D Gaussian Ray Tracing for Tomographic Reconstruction</title><link>https://arxiv.org/abs/2602.01057</link><guid>https://arxiv.org/abs/2602.01057</guid><description>3D Gaussian Splatting (3DGS) has recently emerged in computer vision as a promising rendering technique. By adapting the principles of Elliptical Weighted Average (EWA) splatting to a modern differentiable pipeline, 3DGS enables real-time, high-quality novel view synthesis. Building upon this, R2-Gaussian extended the 3DGS paradigm to tomographic reconstruction by rectifying integration bias, achieving state-of-the-art performance in computed tomography (CT). To enable differentiability, R2-G...</description><pubDate>Sun, 01 Feb 2026 06:53:42 +0000</pubDate><category>Physics</category><category>Rendering</category><author>Ling Chen, Bao Yang</author></item><item><title>HPC: Hierarchical Point-based Latent Representation for Streaming Dynamic Gaussian Splatting Compression</title><link>https://arxiv.org/abs/2602.00671</link><guid>https://arxiv.org/abs/2602.00671</guid><description>While dynamic Gaussian Splatting has driven significant advances in free-viewpoint video, maintaining its rendering quality with a small memory footprint for efficient streaming transmission still presents an ongoing challenge. Existing streaming dynamic Gaussian Splatting compression methods typically leverage a latent representation to drive the neural network for predicting Gaussian residuals between frames. Their core latent representations can be categorized into structured grid-based an...</description><pubDate>Sat, 31 Jan 2026 11:35:02 +0000</pubDate><category>Compression</category><category>Dynamic</category><author>Yangzhi Ma, Bojun Liu, Wenting Liao, Dong Liu, Zhu Li</author><author>Yangzhi Ma, Bojun Liu, Wenting Liao, Dong Liu, Zhu Li et al.</author></item><item><title>Tune-Your-Style: Intensity-tunable 3D Style Transfer with Gaussian Splatting</title><link>https://arxiv.org/abs/2602.00618</link><guid>https://arxiv.org/abs/2602.00618</guid><description>3D style transfer refers to the artistic stylization of 3D assets based on reference style images. Recently, 3DGS-based stylization methods have drawn considerable attention, primarily due to their markedly enhanced training and rendering speeds. However, a vital challenge for 3D style transfer is to strike a balance between the content and the patterns and colors of the style. Although the existing methods strive to achieve relatively balanced outcomes, the fixed-output paradigm struggles to...</description><pubDate>Sat, 31 Jan 2026 09:17:26 +0000</pubDate><category>Editing</category><category>Generation</category><category>Medical</category><author>Yian Zhao, Rushi Ye, Ruochong Zheng, Zesen Cheng, Chaoran Feng</author><author>Yian Zhao, Rushi Ye, Ruochong Zheng, Zesen Cheng, Chaoran Feng et al.</author></item><item><title>PSGS: Text-driven Panorama Sliding Scene Generation via Gaussian Splatting</title><link>https://arxiv.org/abs/2602.00463</link><guid>https://arxiv.org/abs/2602.00463</guid><description>Generating realistic 3D scenes from text is crucial for immersive applications like VR, AR, and gaming. While text-driven approaches promise efficiency, existing methods suffer from limited 3D-text data and inconsistent multi-view stitching, resulting in overly simplistic scenes. To address this, we propose PSGS, a two-stage framework for high-fidelity panoramic scene generation. First, a novel two-layer optimization architecture generates semantically coherent panoramas: a layout reasoning l...</description><pubDate>Sat, 31 Jan 2026 02:34:46 +0000</pubDate><category>Editing</category><category>Generation</category><category>Segmentation</category><author>Xin Zhang, Shen Chen, Jiale Zhou, Lei Li</author></item><item><title>3DGS$^2$-TR: Scalable Second-Order Trust-Region Method for 3D Gaussian Splatting</title><link>https://arxiv.org/abs/2602.00395</link><guid>https://arxiv.org/abs/2602.00395</guid><description>We propose 3DGS$^2$-TR,a second-order optimizer for accelerating the scene training problem in 3D Gaussian Splatting (3DGS). Unlike existing second-order approaches that rely on explicit or dense curvature representations, such as 3DGS-LM (Höllein et al., 2025) or 3DGS2 (Lan et al., 2025), our method approximates curvature using only the diagonal of the Hessian matrix, efficiently via Hutchinson's method. Our approach is fully matrix-free and has the same complexity as ADAM (Kingma, 2024), $O...</description><pubDate>Fri, 30 Jan 2026 23:14:09 +0000</pubDate><author>Roger Hsiao, Yuchen Fang, Xiangru Huang, Ruilong Li, Hesam Rabeti</author><author>Roger Hsiao, Yuchen Fang, Xiangru Huang, Ruilong Li, Hesam Rabeti et al.</author></item><item><title>EAG-PT: Emission-Aware Gaussians and Path Tracing for Indoor Scene Reconstruction and Editing</title><link>https://arxiv.org/abs/2601.23065</link><guid>https://arxiv.org/abs/2601.23065</guid><description>Recent reconstruction methods based on radiance field such as NeRF and 3DGS reproduce indoor scenes with high visual fidelity, but break down under scene editing due to baked illumination and the lack of explicit light transport. In contrast, physically based inverse rendering relies on mesh representations and path tracing, which enforce correct light transport but place strong requirements on geometric fidelity, becoming a practical bottleneck for real indoor scenes. In this work, we propos...</description><pubDate>Fri, 30 Jan 2026 15:16:37 +0000</pubDate><category>Editing</category><category>Medical</category><category>Mesh</category><category>Physics</category><author>Xijie Yang, Mulin Yu, Changjian Jiang, Kerui Ren, Tao Lu</author><author>Xijie Yang, Mulin Yu, Changjian Jiang, Kerui Ren, Tao Lu et al.</author></item><item><title>Self-Supervised Slice-to-Volume Reconstruction with Gaussian Representations for Fetal MRI</title><link>https://arxiv.org/abs/2601.22990</link><guid>https://arxiv.org/abs/2601.22990</guid><description>Reconstructing 3D fetal MR volumes from motion-corrupted stacks of 2D slices is a crucial and challenging task. Conventional slice-to-volume reconstruction (SVR) methods are time-consuming and require multiple orthogonal stacks for reconstruction. While learning-based SVR approaches have significantly reduced the time required at the inference stage, they heavily rely on ground truth information for training, which is inaccessible in practice. To address these challenges, we propose GaussianS...</description><pubDate>Fri, 30 Jan 2026 13:56:44 +0000</pubDate><category>Dynamic</category><category>Medical</category><category>Physics</category><author>Yinsong Wang, Thomas Fletcher, Xinzhe Luo, Aine Travers Dineen, Rhodri Cusack</author><author>Yinsong Wang, Thomas Fletcher, Xinzhe Luo, Aine Travers Dineen, Rhodri Cusack et al.</author></item><item><title>Learning Geometrically-Grounded 3D Visual Representations for View-Generalizable Robotic Manipulation</title><link>https://arxiv.org/abs/2601.22988</link><guid>https://arxiv.org/abs/2601.22988</guid><description>Real-world robotic manipulation demands visuomotor policies capable of robust spatial scene understanding and strong generalization across diverse camera viewpoints. While recent advances in 3D-aware visual representations have shown promise, they still suffer from several key limitations, including reliance on multi-view observations during inference which is impractical in single-view restricted scenarios, incomplete scene modeling that fails to capture holistic and fine-grained geometric s...</description><pubDate>Fri, 30 Jan 2026 13:53:53 +0000</pubDate><category>Editing</category><category>Medical</category><category>Robotics</category><author>Di Zhang, Weicheng Duan, Dasen Gu, Hongye Lu, Hai Zhang</author><author>Di Zhang, Weicheng Duan, Dasen Gu, Hongye Lu, Hai Zhang et al.</author></item><item><title>Diachronic Stereo Matching for Multi-Date Satellite Imagery</title><link>https://arxiv.org/abs/2601.22808</link><guid>https://arxiv.org/abs/2601.22808</guid><description>Recent advances in image-based satellite 3D reconstruction have progressed along two complementary directions. On one hand, multi-date approaches using NeRF or Gaussian-splatting jointly model appearance and geometry across many acquisitions, achieving accurate reconstructions on opportunistic imagery with numerous observations. On the other hand, classical stereoscopic reconstruction pipelines deliver robust and scalable results for simultaneous or quasi-simultaneous image pairs. However, wh...</description><pubDate>Fri, 30 Jan 2026 10:37:20 +0000</pubDate><category>Autonomous Driving</category><category>Dynamic</category><author>Elías Masquil, Luca Savant Aira, Roger Marí, Thibaud Ehret, Pablo Musé</author><author>Elías Masquil, Luca Savant Aira, Roger Marí, Thibaud Ehret, Pablo Musé et al.</author></item><item><title>GaussianOcc3D: A Gaussian-Based Adaptive Multi-modal 3D Occupancy Prediction</title><link>https://arxiv.org/abs/2601.22729</link><guid>https://arxiv.org/abs/2601.22729</guid><description>3D semantic occupancy prediction is a pivotal task in autonomous driving, providing a dense and fine-grained understanding of the surrounding environment, yet single-modality methods face trade-offs between camera semantics and LiDAR geometry. Existing multi-modal frameworks often struggle with modality heterogeneity, spatial misalignment, and the representation crisis--where voxels are computationally heavy and BEV alternatives are lossy. We present GaussianOcc3D, a multi-modal framework bri...</description><pubDate>Fri, 30 Jan 2026 09:05:30 +0000</pubDate><category>Autonomous Driving</category><category>Dynamic</category><category>Segmentation</category><author>A. Enes Doruk, Hasan F. Ates</author></item><item><title>PLANING: A Loosely Coupled Triangle-Gaussian Framework for Streaming 3D Reconstruction</title><link>https://arxiv.org/abs/2601.22046</link><guid>https://arxiv.org/abs/2601.22046</guid><description>Streaming reconstruction from monocular image sequences remains challenging, as existing methods typically favor either high-quality rendering or accurate geometry, but rarely both. We present PLANING, an efficient on-the-fly reconstruction framework built on a hybrid representation that loosely couples explicit geometric primitives with neural Gaussians, enabling geometry and appearance to be modeled in a decoupled manner. This decoupling supports an online initialization and optimization st...</description><pubDate>Thu, 29 Jan 2026 17:47:26 +0000</pubDate><category>Medical</category><category>Mesh</category><category>Physics</category><author>Changjian Jiang, Kerui Ren, Xudong Li, Kaiwen Song, Linning Xu</author><author>Changjian Jiang, Kerui Ren, Xudong Li, Kaiwen Song, Linning Xu et al.</author></item><item><title>Hybrid Foveated Path Tracing with Peripheral Gaussians for Immersive Anatomy</title><link>https://arxiv.org/abs/2601.22026</link><guid>https://arxiv.org/abs/2601.22026</guid><description>Volumetric medical imaging offers great potential for understanding complex pathologies. Yet, traditional 2D slices provide little support for interpreting spatial relationships, forcing users to mentally reconstruct anatomy into three dimensions. Direct volumetric path tracing and VR rendering can improve perception but are computationally expensive, while precomputed representations, like Gaussian Splatting, require planning ahead. Both approaches limit interactive use. We propose a hybrid ...</description><pubDate>Thu, 29 Jan 2026 17:33:14 +0000</pubDate><category>Compression</category><category>Generation</category><category>Medical</category><category>Robotics</category><author>Constantin Kleinbeck, Luisa Theelke, Hannah Schieber, Ulrich Eck, Rüdiger von Eisenhart-Rothe</author><author>Constantin Kleinbeck, Luisa Theelke, Hannah Schieber, Ulrich Eck, Rüdiger von Eisenhart-Rothe et al.</author></item><item><title>Synthetic-to-Real Domain Bridging for Single-View 3D Reconstruction of Ships for Maritime Monitoring</title><link>https://arxiv.org/abs/2601.21786</link><guid>https://arxiv.org/abs/2601.21786</guid><description>Three-dimensional (3D) reconstruction of ships is an important part of maritime monitoring, allowing improved visualization, inspection, and decision-making in real-world monitoring environments. However, most state-ofthe-art 3D reconstruction methods require multi-view supervision, annotated 3D ground truth, or are computationally intensive, making them impractical for real-time maritime deployment. In this work, we present an efficient pipeline for single-view 3D reconstruction of real ship...</description><pubDate>Thu, 29 Jan 2026 14:34:01 +0000</pubDate><category>Segmentation</category><category>Sparse View</category><author>Borja Carrillo-Perez, Felix Sattler, Angel Bueno Rodriguez, Maurice Stephan, Sarah Barnes</author></item><item><title>Learning Physics-Grounded 4D Dynamics with Neural Gaussian Force Fields</title><link>https://arxiv.org/abs/2602.00148</link><guid>https://arxiv.org/abs/2602.00148</guid><description>Predicting physical dynamics from raw visual data remains a major challenge in AI. While recent video generation models have achieved impressive visual quality, they still cannot consistently generate physically plausible videos due to a lack of modeling of physical laws. Recent approaches combining 3D Gaussian splatting and physics engines can produce physically plausible videos, but are hindered by high computational costs in both reconstruction and simulation, and often lack robustness in ...</description><pubDate>Thu, 29 Jan 2026 11:37:41 +0000</pubDate><category>Dynamic</category><category>Generation</category><category>Medical</category><category>Physics</category><author>Shiqian Li, Ruihong Shen, Junfeng Ni, Chang Pan, Chi Zhang</author><author>Shiqian Li, Ruihong Shen, Junfeng Ni, Chang Pan, Chi Zhang et al.</author></item><item><title>Lightweight High-Fidelity Low-Bitrate Talking Face Compression for 3D Video Conference</title><link>https://arxiv.org/abs/2601.21269</link><guid>https://arxiv.org/abs/2601.21269</guid><description>The demand for immersive and interactive communication has driven advancements in 3D video conferencing, yet achieving high-fidelity 3D talking face representation at low bitrates remains a challenge. Traditional 2D video compression techniques fail to preserve fine-grained geometric and appearance details, while implicit neural rendering methods like NeRF suffer from prohibitive computational costs. To address these challenges, we propose a lightweight, high-fidelity, low-bitrate 3D talking ...</description><pubDate>Thu, 29 Jan 2026 05:03:29 +0000</pubDate><category>Compression</category><category>Medical</category><author>Jianglong Li, Jun Xu, Bingcong Lu, Zhengxue Cheng, Hongwei Hu</author><author>Jianglong Li, Jun Xu, Bingcong Lu, Zhengxue Cheng, Hongwei Hu et al.</author></item><item><title>FreeFix: Boosting 3D Gaussian Splatting via Fine-Tuning-Free Diffusion Models</title><link>https://arxiv.org/abs/2601.20857</link><guid>https://arxiv.org/abs/2601.20857</guid><description>Neural Radiance Fields and 3D Gaussian Splatting have advanced novel view synthesis, yet still rely on dense inputs and often degrade at extrapolated views. Recent approaches leverage generative models, such as diffusion models, to provide additional supervision, but face a trade-off between generalization and fidelity: fine-tuning diffusion models for artifact removal improves fidelity but risks overfitting, while fine-tuning-free methods preserve generalization but often yield lower fidelit...</description><pubDate>Wed, 28 Jan 2026 18:56:03 +0000</pubDate><category>Generation</category><category>Medical</category><category>Rendering</category><author>Hongyu Zhou, Zisen Shao, Sheng Miao, Pan Wang, Dongfeng Bai</author><author>Hongyu Zhou, Zisen Shao, Sheng Miao, Pan Wang, Dongfeng Bai et al.</author></item><item><title>GRTX: Efficient Ray Tracing for 3D Gaussian-Based Rendering</title><link>https://arxiv.org/abs/2601.20429</link><guid>https://arxiv.org/abs/2601.20429</guid><description>3D Gaussian Splatting has gained widespread adoption across diverse applications due to its exceptional rendering performance and visual quality. While most existing methods rely on rasterization to render Gaussians, recent research has started investigating ray tracing approaches to overcome the fundamental limitations inherent in rasterization. However, current Gaussian ray tracing methods suffer from inefficiencies such as bloated acceleration structures and redundant node traversals, whic...</description><pubDate>Wed, 28 Jan 2026 09:37:12 +0000</pubDate><category>Rendering</category><author>Junseo Lee, Sangyun Jeon, Jungi Lee, Junyong Park, Jaewoong Sim</author></item><item><title>GVGS: Gaussian Visibility-Aware Multi-View Geometry for Accurate Surface Reconstruction</title><link>https://arxiv.org/abs/2601.20331</link><guid>https://arxiv.org/abs/2601.20331</guid><description>3D Gaussian Splatting enables efficient optimization and high-quality rendering, yet accurate surface reconstruction remains challenging. Prior methods improve surface reconstruction by refining Gaussian depth estimates, either via multi-view geometric consistency or through monocular depth priors. However, multi-view constraints become unreliable under large geometric discrepancies, while monocular priors suffer from scale ambiguity and local inconsistency, ultimately leading to inaccurate G...</description><pubDate>Wed, 28 Jan 2026 07:48:51 +0000</pubDate><category>Avatar</category><category>Mesh</category><author>Mai Su, Qihan Yu, Zhongtao Wang, Yilong Li, Chengwei Pan</author><author>Mai Su, Qihan Yu, Zhongtao Wang, Yilong Li, Chengwei Pan et al.</author></item><item><title>Graphical X Splatting (GraphiXS): A Graphical Model for 4D Gaussian Splatting under Uncertainty</title><link>https://arxiv.org/abs/2601.19843</link><guid>https://arxiv.org/abs/2601.19843</guid><description>We propose a new framework to systematically incorporate data uncertainty in Gaussian Splatting. Being the new paradigm of neural rendering, Gaussian Splatting has been investigated in many applications, with the main effort in extending its representation, improving its optimization process, and accelerating its speed. However, one orthogonal, much needed, but under-explored area is data uncertainty. In standard 4D Gaussian Splatting, data uncertainty can manifest as view sparsity, missing f...</description><pubDate>Tue, 27 Jan 2026 17:50:07 +0000</pubDate><category>Dynamic</category><author>Doga Yilmaz, Jialin Zhu, Deshan Gong, He Wang</author></item></channel></rss>